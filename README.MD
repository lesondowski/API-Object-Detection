# API phÃ¡t hiá»‡n váº­t thá»ƒ (YOLOv11) ğŸ”§

**MÃ´ táº£ ngáº¯n:**
API phÃ¡t hiá»‡n váº­t thá»ƒ sá»­ dá»¥ng mÃ´ hÃ¬nh YOLO (PyTorch / ONNX) vÃ  FastAPI. Nháº­n Ä‘áº§u vÃ o lÃ  danh sÃ¡ch URL áº£nh, tráº£ vá» cÃ¡c váº­t thá»ƒ Ä‘Æ°á»£c phÃ¡t hiá»‡n (sá»‘ lÆ°á»£ng, bounding box/segmentation theo mÃ´ hÃ¬nh).

---

## ğŸ” Äiá»ƒm ná»•i báº­t
- Há»— trá»£ cáº£ mÃ´ hÃ¬nh **PyTorch (.pt)** vÃ  **ONNX (.onnx)**
- API Ä‘Æ¡n giáº£n: POST `/predict/` vá»›i payload chá»©a `image_urls`
- Há»— trá»£ phÃ¢n loáº¡i theo **portion** (vÃ­ dá»¥: "Lon & Chai", "ThÃ¹ng HÃ ng", "Khá»‘i HÃ ng")
- Tá»± Ä‘á»™ng chá»n thiáº¿t bá»‹ (GPU náº¿u cÃ³, ngÆ°á»£c láº¡i CPU)

---

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n (chá»‰ má»¥c chÃ­nh)
- `api/` â€” FastAPI app
  - `main.py` â€” entrypoint (app)
  - `routers/predict_router.py` â€” endpoint `/predict/`
  - `schemas/request_model.py` â€” model request (Pydantic)
- `models/predict.py` â€” logic load áº£nh vÃ  gá»i model (detect/segment)
- `api/files/model/` â€” chá»©a mÃ´ hÃ¬nh (.pt, .onnx, tflite)
- `utils_cf/config.py` â€” cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n mÃ´ hÃ¬nh, DEVICE
- `requirements.txt` â€” dependencies

---

## âš™ï¸ YÃªu cáº§u
- Python >= 3.10  
- GÃ³i (cÃ³ trong `requirements.txt`): `fastapi`, `uvicorn`, `ultralytics`, `onnxruntime`, `opencv-python`, `numpy`, `requests`, `Pillow`, `loguru`, v.v.

CÃ i Ä‘áº·t:

```bash
pip install -r requirements.txt
```

---

## ğŸ›  Cáº¥u hÃ¬nh nhanh
File `utils_cf/config.py` chá»©a:

```python
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MODEL_OD_PT = "api/files/model/pt/ADYL11m.pt"
MODEL_IS_ONNX = "api/files/model/onnx/AD_YL11s_Seg_1.80.onnx"
MODEL_BLOCK_PT = "api/files/model/pt/AD_Productblock_YL11.pt"
```
- Thay Ä‘Æ°á»ng dáº«n náº¿u muá»‘n dÃ¹ng mÃ´ hÃ¬nh khÃ¡c.
- `DEVICE` tá»± phÃ¡t hiá»‡n GPU (náº¿u torch cÃ³ CUDA), báº¡n cÃ³ thá»ƒ Ã©p vá» `"cpu"` khi cáº§n.

---

## â–¶ï¸ Cháº¡y API
Khá»Ÿi cháº¡y server (máº·c Ä‘á»‹nh port 10000 trong cáº¥u hÃ¬nh hiá»‡n táº¡i):

```bash
uvicorn api.main:app --host 0.0.0.0 --port 10000
```
Truy cáº­p gá»‘c: `GET /` (tráº£ vá» thÃ´ng bÃ¡o server Ä‘ang cháº¡y)

---

## ğŸ“¨ Endpoint chÃ­nh

**POST** `/predict/`  
Body (JSON):

```json
{
  "image_urls": ["https://example.com/image1.jpg", "https://example.com/image2.jpg"],
  "conf_input": 0.24,
  "iou_input": 0.2,
  "portion": "Lon & Chai",
  "repuirements_count": 1
}
```
- `image_urls`: danh sÃ¡ch URL áº£nh (báº¯t buá»™c)
- `conf_input`: confidence threshold (máº·c Ä‘á»‹nh ~0.24)
- `iou_input`: IOU threshold (máº·c Ä‘á»‹nh ~0.2)
- `portion`: tÃªn lá»›p tá»•ng há»£p (vÃ­ dá»¥ "Lon & Chai", "ThÃ¹ng HÃ ng", ...)
- `repuirements_count`: sá»‘ lÆ°á»£ng yÃªu cáº§u Ä‘á»ƒ Ä‘Æ°á»£c xem lÃ  "Äáº¡t"

VÃ­ dá»¥ tráº£ vá» (cáº¥u trÃºc máº«u):

```json
{
  "results": [
    { "API URL IMAGE": "https://.../img1.jpg", "Lon & Chai": 2, "OtherClass": 1 },
    { "Sá»‘ LÆ°á»£ng": 2, "Káº¿t Quáº£": "Äáº¡t", "LÃ½ Do": "" }
  ]
}
```

---

## ğŸ§¾ MÃ´ hÃ¬nh kÃ¨m theo (vÃ­ dá»¥ cÃ³ trong repo)
- PT: `api/files/model/pt/ADYL11m.pt`, `AD_Productblock_YL11.pt`, ...
- ONNX: `api/files/model/onnx/AD_YL11s_Seg_1.80.onnx`, ...
- TFLite (saved models) náº±m trong `api/files/model/tflite/...`

---

## ğŸ’¡ Ghi chÃº & hÆ°á»›ng dáº«n gá»¡ lá»—i
- Náº¿u lá»—i táº£i áº£nh: kiá»ƒm tra URL (mÃ£ tráº£ vá» 200). HÃ m `load_image_from_url` sáº½ nÃ©m HTTPException náº¿u táº£i tháº¥t báº¡i.
- Náº¿u muá»‘n cháº¡y hoÃ n toÃ n trÃªn CPU: Ã©p `DEVICE = "cpu"` trong `utils_cf/config.py`.
- Khi dÃ¹ng ONNX, cáº§n `onnxruntime` Ä‘Æ°á»£c cÃ i Ä‘áº·t.

---

## ğŸ“ License & Contact
- Vui lÃ²ng cho biáº¿t loáº¡i license mong muá»‘n (vÃ­ dá»¥ **MIT**) Ä‘á»ƒ tÃ´i cáº­p nháº­t pháº§n `License`.
- Náº¿u cáº§n demo endpoint vá»›i file máº«u, Dockerfile, hoáº·c badge CI, tÃ´i cÃ³ thá»ƒ thÃªm hÆ°á»›ng dáº«n.

---

> Náº¿u báº¡n muá»‘n chá»‰nh sá»­a ná»™i dung (ngÃ´n ngá»¯, thÃªm badges, hoáº·c hÆ°á»›ng dáº«n Docker), cho tÃ´i biáº¿t vÃ  tÃ´i sáº½ cáº­p nháº­t.
